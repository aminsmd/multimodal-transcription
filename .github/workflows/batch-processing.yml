name: Batch Video Processing

on:
  workflow_dispatch:
    inputs:
      max_videos:
        description: 'Maximum videos to process per run'
        required: false
        default: '1'
        type: string
      force_reprocess:
        description: 'Force reprocessing of all videos'
        required: false
        default: false
        type: boolean
  schedule:
    # Run every day at 2 AM UTC (adjust timezone as needed)
    - cron: '0 2 * * *'
  push:
    branches: [ main, develop ]
    paths:
      - 'data/video_database.json'
      - 'src/batch_processor.py'
      - 'src/database/**'
      - 'Dockerfile'
      - 'docker-compose-batch.yml'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  batch-process:
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule' || (github.event_name == 'push' && contains(github.event.head_commit.message, '[batch]'))

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directories
      run: |
        mkdir -p data/videos
        mkdir -p outputs
        mkdir -p logs

    - name: Download test videos (if not present)
      run: |
        # This step would download videos from your storage
        # For now, we'll assume videos are already in the repository
        echo "Videos should be present in data/videos/"

    - name: Run batch processing
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        python src/batch_processor.py \
          --database data/video_database.json \
          --base-dir outputs \
          --data-dir data \
          --max-videos ${{ github.event.inputs.max_videos || '1' }} \
          --verbose

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: batch-processing-results-${{ github.run_number }}
        path: |
          outputs/
          data/video_database.json
        retention-days: 30

    - name: Update database status
      run: |
        echo "Database updated with processing results"
        # Here you could commit the updated database back to the repository
        # or send results to a webhook/API

  docker-batch-process:
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.use_docker == 'true'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Pull Docker image
      run: |
        docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest

    - name: Create data directories
      run: |
        mkdir -p data/videos
        mkdir -p outputs
        mkdir -p logs

    - name: Run Docker batch processing
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        docker run --rm \
          -v $(pwd)/data:/app/data \
          -v $(pwd)/outputs:/app/outputs \
          -v $(pwd)/logs:/app/logs \
          -e GOOGLE_API_KEY=$GOOGLE_API_KEY \
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest \
          python src/batch_processor.py \
            --database /app/data/video_database.json \
            --base-dir /app/outputs \
            --data-dir /app/data \
            --max-videos ${{ github.event.inputs.max_videos || '1' }} \
            --verbose

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: docker-batch-results-${{ github.run_number }}
        path: |
          outputs/
          data/video_database.json
        retention-days: 30
