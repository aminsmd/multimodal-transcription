name: Deploy and Test

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Processing mode'
        required: true
        default: 'single'
        type: choice
        options:
          - single
          - batch
      video:
        description: 'Video to test (only for single mode)'
        required: false
        default: 'adam'
        type: choice
        options:
          - adam
          - angela
          - audrey

env:
  AWS_REGION: us-east-2
  ECR_REPOSITORY: multimodal-transcription
  S3_BUCKET: multimodal-transcription-videos-1761690600
  ECS_CLUSTER: multimodal-transcription-cluster
  VPC_ID: vpc-f2452499
  SUBNET_IDS: subnet-9b7957d7,subnet-e74bc28c,subnet-8135f2fc
  SECURITY_GROUP_ID: sg-0b638085b666a013f

jobs:
  deploy-and-test:
    name: Deploy and Test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set video path or batch mode
      id: video-path
      run: |
        MODE="${{ github.event.inputs.mode || 'single' }}"
        echo "mode=$MODE" >> $GITHUB_OUTPUT
        
        if [ "$MODE" = "batch" ]; then
          echo "üîÑ Batch processing mode enabled"
          echo "video-name=batch" >> $GITHUB_OUTPUT
          echo "video-path=" >> $GITHUB_OUTPUT
        else
          echo "üé¨ Single video mode"
          case "${{ github.event.inputs.video || 'adam' }}" in
            "adam")
              echo "video-path=test-videos/Adam_2024-03-03_6_32_PM.mp4" >> $GITHUB_OUTPUT
              echo "video-name=Adam" >> $GITHUB_OUTPUT
              ;;
            "angela")
              echo "video-path=test-videos/Angela_2025-03-10_2_11_PM.mp4" >> $GITHUB_OUTPUT
              echo "video-name=Angela" >> $GITHUB_OUTPUT
              ;;
            "audrey")
              echo "video-path=test-videos/Audrey_2025-04-06_6_20_PM-2.mp4" >> $GITHUB_OUTPUT
              echo "video-name=Audrey" >> $GITHUB_OUTPUT
              ;;
          esac
        fi

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Build and push Docker image
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "Building Docker image..."
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        echo "Pushing to ECR..."
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        echo "image-uri=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

    - name: Create ECS cluster if it doesn't exist
      run: |
        echo "üîß Ensuring ECS cluster exists..."
        aws ecs describe-clusters --clusters ${{ env.ECS_CLUSTER }} || \
        aws ecs create-cluster --cluster-name ${{ env.ECS_CLUSTER }}

    - name: Ensure ECS task execution role exists
      run: |
        echo "üîß Ensuring ECS task execution role exists..."
        ROLE_NAME="ecsTaskExecutionRole"
        ROLE_ARN="arn:aws:iam::669655810547:role/$ROLE_NAME"
        
        # Check if role exists
        if aws iam get-role --role-name $ROLE_NAME &>/dev/null; then
          echo "‚úÖ Role $ROLE_NAME already exists"
          
          # Update trust policy if needed
          echo "üìù Updating trust policy..."
          aws iam update-assume-role-policy \
            --role-name $ROLE_NAME \
            --policy-document '{
              "Version": "2012-10-17",
              "Statement": [{
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }]
            }'
        else
          echo "üÜï Creating role $ROLE_NAME..."
          
          # Create role with trust policy
          aws iam create-role \
            --role-name $ROLE_NAME \
            --assume-role-policy-document '{
              "Version": "2012-10-17",
              "Statement": [{
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }]
            }'
        fi
        
        # Attach managed policy for ECS task execution
        echo "üìã Attaching AWS managed policy..."
        aws iam attach-role-policy \
          --role-name $ROLE_NAME \
          --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy || \
          echo "Policy already attached or attach failed (may need manual setup)"
        
        # Attach inline policy for Secrets Manager access (required for retrieving secrets)
        echo "üìã Attaching Secrets Manager inline policy..."
        # Use wildcard pattern to match secret ARN with any suffix (AWS adds random suffix)
        SECRET_ARN_PATTERN="arn:aws:secretsmanager:${{ env.AWS_REGION }}:669655810547:secret:google-api-key*"
        
        # Create inline policy document with wildcard pattern to match any suffix
        # Use printf to avoid YAML parsing issues with heredocs
        printf '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Action":["secretsmanager:GetSecretValue","secretsmanager:DescribeSecret"],"Resource":"%s"}]}' "$SECRET_ARN_PATTERN" > secrets-policy.json
        
        # Attach inline policy
        aws iam put-role-policy \
          --role-name $ROLE_NAME \
          --policy-name SecretsManagerAccess \
          --policy-document file://secrets-policy.json || \
          echo "Secrets Manager policy already attached or attach failed (may need manual setup)"
        
        rm -f secrets-policy.json
        
        # Allow time for IAM changes to propagate (especially important for newly created roles)
        # AWS recommends 30-60 seconds for full IAM propagation across all services
        echo "‚è≥ Waiting for IAM execution role changes to propagate (30 seconds)..."
        sleep 30
        
        echo "‚úÖ ECS task execution role is ready: $ROLE_ARN"
        
        # Also ensure task role exists (for container AWS API access)
        echo "üîß Ensuring ECS task role exists..."
        TASK_ROLE_NAME="ecsTaskRole"
        TASK_ROLE_ARN="arn:aws:iam::669655810547:role/$TASK_ROLE_NAME"
        
        if aws iam get-role --role-name $TASK_ROLE_NAME &>/dev/null; then
          echo "‚úÖ Task role $TASK_ROLE_NAME already exists"
          # Role exists, but ensure trust policy is correct
          echo "üìù Updating trust policy for existing task role..."
          aws iam update-assume-role-policy \
            --role-name $TASK_ROLE_NAME \
            --policy-document '{
              "Version": "2012-10-17",
              "Statement": [{
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }]
            }'
        else
          echo "üÜï Creating task role $TASK_ROLE_NAME..."
          aws iam create-role \
            --role-name $TASK_ROLE_NAME \
            --assume-role-policy-document '{
              "Version": "2012-10-17",
              "Statement": [{
                "Effect": "Allow",
                "Principal": {
                  "Service": "ecs-tasks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }]
            }'
          
          # Attach S3 full access policy (for reading input and writing output)
          echo "üìã Attaching S3 access policy to task role..."
          aws iam attach-role-policy \
            --role-name $TASK_ROLE_NAME \
            --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess || \
            echo "S3 policy attach failed (may need manual setup)"
        fi
        
        # Allow time for IAM changes to propagate (especially important for newly created roles)
        # AWS recommends 30-60 seconds for full IAM propagation across all services
        echo "‚è≥ Waiting for IAM task role changes to propagate (30 seconds)..."
        sleep 30
        
        # Verify the role can be retrieved (helps confirm propagation)
        echo "üîç Verifying task role is accessible..."
        aws iam get-role --role-name $TASK_ROLE_NAME --query 'Role.Arn' --output text
        
        echo "‚úÖ ECS task role is ready: $TASK_ROLE_ARN"

    - name: Verify IAM roles are ready
      run: |
        echo "üîç Performing final verification of IAM roles..."
        EXEC_ROLE=$(aws iam get-role --role-name ecsTaskExecutionRole --query 'Role.Arn' --output text)
        TASK_ROLE=$(aws iam get-role --role-name ecsTaskRole --query 'Role.Arn' --output text)
        echo "‚úÖ Execution role: $EXEC_ROLE"
        echo "‚úÖ Task role: $TASK_ROLE"
        echo "‚è≥ Final wait to ensure IAM propagation across all AWS services (15 seconds)..."
        sleep 15

    - name: Create or update Secrets Manager secret from GitHub
      id: secret-arn
      run: |
        echo "üîê Creating or updating AWS Secrets Manager secret from GitHub..."
        
        SECRET_NAME="google-api-key"
        SECRET_VALUE="${{ secrets.GOOGLE_API_KEY }}"
        
        if [ -z "$SECRET_VALUE" ]; then
          echo "‚ùå ERROR: GOOGLE_API_KEY GitHub secret is not set"
          echo "Please add GOOGLE_API_KEY to your GitHub repository secrets"
          exit 1
        fi
        
        # Check if secret already exists
        EXISTING_SECRET=$(aws secretsmanager describe-secret \
          --secret-id $SECRET_NAME \
          --region ${{ env.AWS_REGION }} \
          --query 'ARN' \
          --output text 2>&1 || echo "")
        
        if [[ "$EXISTING_SECRET" =~ "arn:aws:secretsmanager" ]]; then
          echo "‚úÖ Secret exists: $EXISTING_SECRET"
          echo "üìù Updating secret value..."
          # Update existing secret
          aws secretsmanager put-secret-value \
            --secret-id $SECRET_NAME \
            --secret-string "$SECRET_VALUE" \
            --region ${{ env.AWS_REGION }} > /dev/null
          SECRET_ARN="$EXISTING_SECRET"
        else
          echo "üÜï Creating new secret..."
          # Create new secret
          SECRET_ARN=$(aws secretsmanager create-secret \
            --name $SECRET_NAME \
            --secret-string "$SECRET_VALUE" \
            --region ${{ env.AWS_REGION }} \
            --query 'ARN' \
            --output text)
          echo "‚úÖ Created secret: $SECRET_ARN"
        fi
        
        # Verify the ARN has the required suffix format
        if [[ ! "$SECRET_ARN" =~ -[A-Za-z0-9]{6}$ ]]; then
          echo "‚ö†Ô∏è WARNING: Secret ARN may not have the required suffix format"
          echo "ARN: $SECRET_ARN"
        fi
        
        echo "‚úÖ Secret ARN ready: $SECRET_ARN"
        echo "secret-arn=$SECRET_ARN" >> $GITHUB_OUTPUT

    - name: Create dynamic task definition
      id: task-def
      run: |
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        MODE="${{ steps.video-path.outputs.mode }}"
        
        if [ "$MODE" = "batch" ]; then
          OUTPUT_PREFIX="batch-outputs/$TIMESTAMP"
          echo "üîÑ Batch processing mode"
          echo "üìÅ S3 output: s3://${{ env.S3_BUCKET }}/$OUTPUT_PREFIX/"
          echo "üîë Using secret ARN: ${{ steps.secret-arn.outputs.secret-arn }}"
          
          # Build command string for batch processing
          # The batch processor will fetch videos from API, download from S3, process, and send notifications
          CMD_STRING='mkdir -p /tmp/outputs && python src/batch_transcription_processor.py --output-dir /tmp/outputs --chunk-size 600 --max-workers 2 && aws s3 sync /tmp/outputs "s3://$S3_BUCKET/$S3_OUTPUT_PREFIX" --exclude '"'"'*.mp4'"'"' --exclude '"'"'*.mov'"'"' --exclude '"'"'*.avi'"'"' --exclude '"'"'*.mkv'"'"' --exclude '"'"'*.webm'"'"' --exclude '"'"'*.m4v'"'"' --exclude '"'"'videos/*'"'"' --exclude '"'"'chunks/*'"'"' --delete'
        else
          OUTPUT_PREFIX="test-outputs/${{ steps.video-path.outputs.video-name }}-$TIMESTAMP"
          echo "üé¨ Testing video: ${{ steps.video-path.outputs.video-name }}"
          echo "üìÅ S3 output: s3://${{ env.S3_BUCKET }}/$OUTPUT_PREFIX/"
          echo "üîë Using secret ARN: ${{ steps.secret-arn.outputs.secret-arn }}"
          
          # Build command string for single video processing
          CMD_STRING='mkdir -p /tmp/video /tmp/outputs && VIDEO_FILENAME=$(basename "$S3_VIDEO_PATH") && aws s3 cp "s3://$S3_BUCKET/$S3_VIDEO_PATH" "/tmp/video/$VIDEO_FILENAME" && python src/transcription_pipeline.py --input "/tmp/video/$VIDEO_FILENAME" --output-dir /tmp/outputs --chunk-size 600 --max-workers 2 && aws s3 sync /tmp/outputs "s3://$S3_BUCKET/$S3_OUTPUT_PREFIX" --exclude '"'"'*.mp4'"'"' --exclude '"'"'*.mov'"'"' --exclude '"'"'*.avi'"'"' --exclude '"'"'*.mkv'"'"' --exclude '"'"'*.webm'"'"' --exclude '"'"'*.m4v'"'"' --exclude '"'"'videos/*'"'"' --exclude '"'"'chunks/*'"'"' --delete'
        fi
        
        # Get S3_BUCKET_PATH from secrets (for batch processing - this is the SOURCE bucket for reading videos)
        # Note: S3_BUCKET is the DESTINATION bucket for writing outputs
        S3_BUCKET_PATH_VALUE="${{ secrets.S3_BUCKET_PATH }}"
        if [ -z "$S3_BUCKET_PATH_VALUE" ]; then
          # Fallback: construct from bucket name if secret not set
          # But this should ideally be set to the source bucket (bci-prod-upload)
          S3_BUCKET_PATH_VALUE="s3://${{ env.S3_BUCKET }}"
        fi
        
        # Create task definition using jq for proper JSON escaping
        jq -n \
          --arg family "multimodal-transcription-test-$(date +%s)" \
          --arg image "${{ steps.build-image.outputs.image-uri }}" \
          --arg aws_region "${{ env.AWS_REGION }}" \
          --arg s3_bucket "${{ env.S3_BUCKET }}" \
          --arg output_prefix "${OUTPUT_PREFIX}" \
          --arg video_path "${{ steps.video-path.outputs.video-path }}" \
          --arg s3_bucket_path "$S3_BUCKET_PATH_VALUE" \
          --arg secret_arn "${{ steps.secret-arn.outputs.secret-arn }}" \
          --arg cmd_string "$CMD_STRING" \
          '{
            "family": $family,
            "networkMode": "awsvpc",
            "requiresCompatibilities": ["FARGATE"],
            "cpu": "2048",
            "memory": "4096",
            "executionRoleArn": "arn:aws:iam::669655810547:role/ecsTaskExecutionRole",
            "taskRoleArn": "arn:aws:iam::669655810547:role/ecsTaskRole",
            "containerDefinitions": [
              {
                "name": "multimodal-transcription",
                "image": $image,
                "essential": true,
                "logConfiguration": {
                  "logDriver": "awslogs",
                  "options": {
                    "awslogs-group": "/ecs/multimodal-transcription-test",
                    "awslogs-region": $aws_region,
                    "awslogs-stream-prefix": "ecs"
                  }
                },
                "environment": [
                  {"name": "PYTHONUNBUFFERED", "value": "1"},
                  {"name": "AWS_DEFAULT_REGION", "value": $aws_region},
                  {"name": "S3_BUCKET", "value": $s3_bucket},
                  {"name": "S3_OUTPUT_PREFIX", "value": $output_prefix},
                  {"name": "S3_VIDEO_PATH", "value": $video_path},
                  {"name": "S3_BUCKET_PATH", "value": $s3_bucket_path}
                ],
                "secrets": [
                  {"name": "GOOGLE_API_KEY", "valueFrom": $secret_arn}
                ],
                "command": ["sh", "-c", $cmd_string]
              }
            ]
          }' > temp-task-definition.json
        
        # Validate JSON was created successfully
        if [ ! -s temp-task-definition.json ]; then
          echo "‚ùå ERROR: Failed to create task definition JSON"
          exit 1
        fi
        
        # Validate JSON syntax
        if ! jq empty temp-task-definition.json 2>/dev/null; then
          echo "‚ùå ERROR: Invalid JSON in task definition"
          cat temp-task-definition.json
          exit 1
        fi
        
        echo "OUTPUT_PREFIX=$OUTPUT_PREFIX" >> $GITHUB_ENV
        echo "output-prefix=$OUTPUT_PREFIX" >> $GITHUB_OUTPUT

    - name: Register and run ECS task
      run: |
        echo "üìã Registering task definition..."
        TASK_DEF_ARN=$(aws ecs register-task-definition \
          --cli-input-json file://temp-task-definition.json \
          --query 'taskDefinition.taskDefinitionArn' \
          --output text)
        
        echo "‚úÖ Task definition registered: $TASK_DEF_ARN"
        
        echo "üöÄ Starting ECS task..."
        TASK_ARN=$(aws ecs run-task \
          --cluster ${{ env.ECS_CLUSTER }} \
          --task-definition $TASK_DEF_ARN \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[${{ env.SUBNET_IDS }}],securityGroups=[${{ env.SECURITY_GROUP_ID }}],assignPublicIp=ENABLED}" \
          --query 'tasks[0].taskArn' \
          --output text)
        
        echo "‚úÖ ECS task started: $TASK_ARN"
        
        # Wait for task to complete
        echo "‚è≥ Waiting for task to complete..."
        aws ecs wait tasks-stopped \
          --cluster ${{ env.ECS_CLUSTER }} \
          --tasks $TASK_ARN
        
        # Get task status and details
        TASK_STATUS=$(aws ecs describe-tasks \
          --cluster ${{ env.ECS_CLUSTER }} \
          --tasks $TASK_ARN \
          --query 'tasks[0].lastStatus' \
          --output text)
        
        EXIT_CODE=$(aws ecs describe-tasks \
          --cluster ${{ env.ECS_CLUSTER }} \
          --tasks $TASK_ARN \
          --query 'tasks[0].containers[0].exitCode' \
          --output text)
        
        # Get stop code and reason for better debugging
        STOP_CODE=$(aws ecs describe-tasks \
          --cluster ${{ env.ECS_CLUSTER }} \
          --tasks $TASK_ARN \
          --query 'tasks[0].stopCode' \
          --output text)
        
        STOPPED_REASON=$(aws ecs describe-tasks \
          --cluster ${{ env.ECS_CLUSTER }} \
          --tasks $TASK_ARN \
          --query 'tasks[0].stoppedReason' \
          --output text)
        
        # Extract task ID from ARN (last part after final slash) for log stream prefix
        TASK_ID=$(echo $TASK_ARN | awk -F'/' '{print $NF}')
        
        # Check if task succeeded (exit code 0 or null might mean container didn't start)
        if [ "$TASK_STATUS" = "STOPPED" ] && [ "$EXIT_CODE" = "0" ]; then
          echo "‚úÖ ECS task completed successfully!"
        else
          echo "‚ùå ECS task failed with status: $TASK_STATUS, exit code: $EXIT_CODE"
          echo "üìã Stop code: $STOP_CODE"
          echo "üìã Stopped reason: $STOPPED_REASON"
          
          # Get task logs for debugging
          echo "üìã Fetching task logs..."
          # Extract task ID from ARN (last part after final slash)
          # Log stream format is typically: {prefix}/{container-name}/{task-id}
          # Try multiple patterns to find the log stream
          LOG_STREAM_NAME=""
          
          # Try with prefix pattern
          LOG_STREAM_NAME=$(aws logs describe-log-streams \
            --log-group-name "/ecs/multimodal-transcription-test" \
            --log-stream-name-prefix "ecs/multimodal-transcription" \
            --order-by LastEventTime \
            --descending \
            --max-items 10 \
            --query "logStreams[?contains(logStreamName, '$TASK_ID')].logStreamName" \
            --output text 2>/dev/null | head -1 || echo "")
          
          # If not found, try searching by task ID directly
          if [ -z "$LOG_STREAM_NAME" ] || [ "$LOG_STREAM_NAME" = "None" ]; then
            LOG_STREAM_NAME=$(aws logs describe-log-streams \
              --log-group-name "/ecs/multimodal-transcription-test" \
              --order-by LastEventTime \
              --descending \
              --max-items 20 \
              --query "logStreams[?contains(logStreamName, '$TASK_ID')].logStreamName" \
              --output text 2>/dev/null | head -1 || echo "")
          fi
          
          if [ ! -z "$LOG_STREAM_NAME" ] && [ "$LOG_STREAM_NAME" != "None" ] && [ "$LOG_STREAM_NAME" != "" ]; then
            echo "üìÑ Last 50 lines of logs from: $LOG_STREAM_NAME"
            aws logs get-log-events \
              --log-group-name "/ecs/multimodal-transcription-test" \
              --log-stream-name "$LOG_STREAM_NAME" \
              --start-from-head \
              --query 'events[*].message' \
              --output text | tail -50
          else
            echo "‚ö†Ô∏è Could not find logs for task ID: $TASK_ID"
            echo "üìã Listing recent log streams:"
            aws logs describe-log-streams \
              --log-group-name "/ecs/multimodal-transcription-test" \
              --order-by LastEventTime \
              --descending \
              --max-items 5 \
              --query 'logStreams[*].[logStreamName,lastEventTime]' \
              --output table 2>/dev/null || echo "Could not list log streams"
          fi
          
          exit 1
        fi
        
        # Clean up temporary file
        rm -f temp-task-definition.json

    - name: Clean up old ECR images
      run: |
        echo "üßπ Cleaning up old ECR images..."
        
        # Get current image digest using the image URI
        CURRENT_IMAGE_DIGEST=$(aws ecr describe-images --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --query 'imageDetails[0].imageDigest' --output text)
        
        if [ "$CURRENT_IMAGE_DIGEST" != "None" ] && [ ! -z "$CURRENT_IMAGE_DIGEST" ]; then
          echo "Current image digest: $CURRENT_IMAGE_DIGEST"
          
          # List all images except the current one
          ALL_IMAGES=$(aws ecr list-images --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --query 'imageIds[?imageDigest!=`'$CURRENT_IMAGE_DIGEST'`].imageDigest' --output text)
          
          if [ ! -z "$ALL_IMAGES" ]; then
            echo "Deleting old images..."
            for digest in $ALL_IMAGES; do
              echo "Deleting: $digest"
              aws ecr batch-delete-image --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} --image-ids imageDigest=$digest || echo "Failed to delete $digest (may be referenced by manifest list)"
            done
          else
            echo "No old images to clean up"
          fi
        else
          echo "No current image found, skipping cleanup"
        fi
        
        echo "‚úÖ ECR cleanup completed"

    - name: Clean up unused CloudWatch log groups
      run: |
        echo "üßπ Cleaning up unused CloudWatch log groups..."
        
        # List of log groups to clean up (keep only the ones we're using)
        LOG_GROUPS_TO_DELETE=(
          "/ecs/multimodal-transcription-simple"
          "/ecs/batch-transcription"
        )
        
        for log_group in "${LOG_GROUPS_TO_DELETE[@]}"; do
          echo "Checking log group: $log_group"
          if aws logs describe-log-groups --log-group-name-prefix "$log_group" --region ${{ env.AWS_REGION }} --query 'logGroups[0].logGroupName' --output text | grep -q "$log_group"; then
            echo "Deleting log group: $log_group"
            aws logs delete-log-group --log-group-name "$log_group" --region ${{ env.AWS_REGION }} || echo "Failed to delete $log_group (may have active streams)"
          else
            echo "Log group $log_group not found or already deleted"
          fi
        done
        
        echo "‚úÖ CloudWatch cleanup completed"

    - name: Show results
      run: |
        echo "‚úÖ ECS test completed successfully!"
        echo "üé¨ Video: ${{ steps.video-path.outputs.video-name }}"
        echo "üì¶ Image: ${{ steps.build-image.outputs.image-uri }}"
        echo "üìÅ Results: s3://${{ env.S3_BUCKET }}/${{ steps.task-def.outputs.output-prefix }}/"
        echo "üèóÔ∏è ECS Cluster: ${{ env.ECS_CLUSTER }}"
        echo ""
        echo "üìã S3 Output files:"
        aws s3 ls "s3://${{ env.S3_BUCKET }}/${{ steps.task-def.outputs.output-prefix }}/" --recursive || echo "No files found"
